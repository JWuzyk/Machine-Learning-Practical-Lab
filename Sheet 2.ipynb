{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defines function used in one step algorithm with function input a vector z\n",
    "def SVMfunc(z, x, y, beta, bias):\n",
    "    return (bias + sum(beta[l]*y[l]*np.dot(z, x[l]) for l in range(len(beta))))\n",
    "\n",
    "def SVMfunc2(z, x, y, beta, bias):\n",
    "    ans=bias+(y*(z@x.T))@beta\n",
    "    return(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OneStep(i,j, x, y, beta, bias, C):\n",
    "    delta = y[i]*((SVMfunc(x[j], x, y, beta, bias)-y[j]) - (SVMfunc(x[i], x, y, beta, bias) - y[i]))\n",
    "    s = y[i]*y[j]\n",
    "    chi = np.dot(x[i],x[i]) + np.dot(x[j],x[j]) - 2*np.dot(x[i],x[j])\n",
    "    gamma = s*beta[i] + beta[j]\n",
    "    \n",
    "    if s==1:\n",
    "        L= max(0, gamma -1*C)\n",
    "        H = min(gamma, C)\n",
    "    \n",
    "    else:\n",
    "        L = max(0, -1*gamma)\n",
    "        H = min(C, C-gamma)\n",
    "    \n",
    "    if chi>0:\n",
    "        beta[i] = min(max(beta[i] + delta/chi, L), H)\n",
    "    elif delta > 0:\n",
    "        beta_new[i] = L\n",
    "    else:\n",
    "        beta[i] = H\n",
    "    beta[j] = gamma - s * beta[i]\n",
    "    bias = bias - 0.5 * (SVMfunc(x[j], x, y, beta, bias) - y[j] + SVMfunc(x[i], x, y, beta, bias) - y[i])\n",
    "    return (beta, bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draws \n",
    "def expTestData(SampleSize, scale1, scale2):\n",
    "    #draw SampleSize by 2 points according to exp distribution with lambda =4,0.5 resp.\n",
    "    x1 = np.random.exponential(scale=scale1, size = (SampleSize,2))\n",
    "    x2 = np.random.exponential(scale=scale2, size = (SampleSize,2))\n",
    "\n",
    "    #label points in x1 by -1 and points in x2 by 1\n",
    "    y2 = np.ones(SampleSize)\n",
    "    y1 = np.full(SampleSize, -1)\n",
    "\n",
    "    #join all data points into x matrix and y matrix\n",
    "    x = np.concatenate((x1, x2), axis =0)\n",
    "    y = np.concatenate((y1, y2), axis=0)\n",
    "    \n",
    "    return(x,y)\n",
    "\n",
    "x, y = expTestData(20, 0.25, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SMO(x, y, iterations, C):\n",
    "    n = len(x)\n",
    "    beta = np.zeros(n)\n",
    "    bias = 0\n",
    "    \n",
    "    for k in range(iterations):\n",
    "        #picks two non equal integers from 0 to n\n",
    "        i, j = np.random.choice(n, 2)\n",
    "        \n",
    "        #updates beta and bias according to onestep algorithm\n",
    "        beta, bias = OneStep(i,j, x, y, beta, bias, C)\n",
    "    \n",
    "    s=(SVMfunc2(x,x,y,beta,bias)-y)[beta!=0]\n",
    "    bias=bias-np.median(s)\n",
    "    \n",
    "    return (beta,bias)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_testdata, y_testdata = expTestData(1000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conplot(x,y,iterations,C):\n",
    "    beta,bias=SMO(x,y,iterations,C)\n",
    "    \n",
    "    maxx = np.amax(x[:,0])\n",
    "    maxy = np.amax(x[:,1])\n",
    "    minx = np.amin(x[:,0])\n",
    "    miny = np.amin(x[:,1])    \n",
    "    t = np.arange(minx-1, maxx+1, 0.1)\n",
    "    s = np.arange(miny-1, maxy+1, 0.1)\n",
    "    p,q = np.meshgrid(t, s)\n",
    "    z = SVMfunc2(np.stack((p,q), axis=2),x,y,beta,bias)\n",
    "    plt.contourf(t,s,z,[-99999,0,99999], colors=['blue','red'],alpha=0.5)\n",
    "    plt.plot(x[y==-1][:,0],x[y==-1][:,1],'bo',x[y==1][:,0],x[y==1][:,1],'ro')\n",
    "\n",
    "def conplot3(x,y,iterations,C):\n",
    "    beta,bias=SMO(x,y,iterations,C)\n",
    "    \n",
    "    maxx = np.amax(x[:,0])\n",
    "    maxy = np.amax(x[:,1])\n",
    "    minx = np.amin(x[:,0])\n",
    "    miny = np.amin(x[:,1])    \n",
    "    t = np.arange(minx-1, maxx+1, 0.1)\n",
    "    s = np.arange(miny-1, maxy+1, 0.1)\n",
    "    p,q = np.meshgrid(t, s)\n",
    "    z = SVMfunc2(np.stack((p,q,p**2+q**2), axis=2),x,y,beta,bias)\n",
    "    plt.contourf(t,s,z,[-99999,0,99999], colors=['blue','red'],alpha=0.5)\n",
    "    plt.plot(x[y==-1][:,0],x[y==-1][:,1],'bo',x[y==1][:,0],x[y==1][:,1],'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data, take a uniform distribution on [0,1]x[0,2\\pi], scale 1st coord by sqrt( to get uniform dist on disk) and map to circle using polar coords\n",
    "\n",
    "n= 50 #number of samples\n",
    "x= np.random.uniform(0,1,n)\n",
    "x=x**0.5\n",
    "y= np.random.uniform(0,2*np.pi,n)\n",
    "yd=x*np.sin(y)\n",
    "xd=x*np.cos(y)\n",
    "X1= np.vstack((xd,yd)).T\n",
    "X1lbl=-1*np.ones(n)\n",
    "\n",
    "#similarly for annulus\n",
    "x= np.random.uniform(1,4,n)\n",
    "x=x**0.5\n",
    "y= np.random.uniform(0,2*np.pi,n)\n",
    "yd=x*np.sin(y)\n",
    "xd=x*np.cos(y)\n",
    "X2= np.vstack((xd,yd)).T\n",
    "X2lbl=np.ones(n)\n",
    "#label X1 by -1 and X2 by 1\n",
    "\n",
    "\n",
    "X_Data = np.concatenate((X1,X2))\n",
    "Y_Data = np.concatenate((X1lbl,X2lbl))\n",
    "\n",
    "plt.plot(X_Data[Y_Data==-1][:,0],X_Data[Y_Data==-1][:,1],'ro',X_Data[Y_Data==1][:,0],X_Data[Y_Data==1][:,1],'bo')\n",
    "\n",
    "#circle1=plt.Circle((0,0),2,color='g')\n",
    "#plt.gcf().gca().add_artist(circle1)\n",
    "#circle2=plt.Circle((0,0),1,color='y')\n",
    "#plt.gcf().gca().add_artist(circle2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conplot(X_Data,Y_Data,100,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Trans = np.stack((X_Data[:,0],X_Data[:,1],X_Data[:,0]**2+X_Data[:,1]**2)).T\n",
    "\n",
    "conplot3(X_Trans,Y_Data,100,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The map $\\phi$ maps to a parabaloid. It adds the 2-norm of points as a parameter and this easily disinguishes the two data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMfunc_NL(z, x, y, beta, bias, kernel):\n",
    "    ans=bias+(y*(kernel(z,x)))@beta\n",
    "    return(ans)\n",
    "\n",
    "def OneStep_NL(i,j, x, y, beta, bias, C,kernel):\n",
    "    delta = y[i]*((SVMfunc_NL(x[j], x, y, beta, bias,kernel)-y[j]) - (SVMfunc_NL(x[i], x, y, beta, bias,kernel) - y[i]))\n",
    "    s = y[i]*y[j]\n",
    "    chi = kernel(x[i],x[i]) + kernel(x[j],x[j]) - 2*kernel(x[i],x[j])\n",
    "    gamma = s*beta[i] + beta[j]\n",
    "    \n",
    "    if s==1:\n",
    "        L= max(0, gamma -1*C)\n",
    "        H = min(gamma, C)\n",
    "    \n",
    "    else:\n",
    "        L = max(0, -1*gamma)\n",
    "        H = min(C, C-gamma)\n",
    "    \n",
    "    if chi>0:\n",
    "        beta[i] = min(max(beta[i] + delta/chi, L), H)\n",
    "    elif delta > 0:\n",
    "        beta[i] = L\n",
    "    else:\n",
    "        beta[i] = H\n",
    "        \n",
    "    beta[j] = gamma - s * beta[i]\n",
    "    bias = bias - 0.5 * (SVMfunc_NL(x[j], x, y, beta, bias, kernel) - y[j] + SVMfunc_NL(x[i], x, y, beta, bias,kernel) - y[i])\n",
    "    return (beta, bias)\n",
    "\n",
    "\n",
    "def SMO_NL(x, y, iterations, C,kernel):\n",
    "    n = len(x)\n",
    "    beta = np.zeros(n)\n",
    "    bias = 0\n",
    "    \n",
    "    for k in range(iterations):\n",
    "        #picks two non equal integers from 0 to n\n",
    "        i, j = np.random.choice(n, 2)\n",
    "        \n",
    "        #updates beta and bias according to onestep algorithm\n",
    "        beta, bias = OneStep_NL(i,j, x, y, beta, bias, C,kernel)\n",
    "    \n",
    "    s=(SVMfunc_NL(x,x,y,beta,bias,kernel)-y)[beta!=0]\n",
    "    bias=bias-np.median(s)\n",
    "    \n",
    "    return (beta,bias)\n",
    "\n",
    "def norm(x):\n",
    "    return np.sum(x*x,axis=len(x.shape)-1)\n",
    "    \n",
    "def GaussKernel(z,x,sigma):\n",
    "    xt=x.reshape(tuple(np.ones(len(z.shape)-1).astype(int))+x.shape)\n",
    "    zt=z.reshape(z.shape[:-1]+(1,)+(z.shape[-1],))  \n",
    "    return np.exp(-norm(zt-xt)/(2*sigma**2))\n",
    "\n",
    "def ScalarProdKernel(z,x):\n",
    "    return z@x.T\n",
    "\n",
    "def Gauss1(z,x):\n",
    "    return GaussKernel(z,x,1)\n",
    "\n",
    "def conplot_NL(x,y,iterations,C,kernel):\n",
    "    beta,bias=SMO_NL(x,y,iterations,C,kernel)\n",
    "    \n",
    "    maxx = np.amax(x[:,0])\n",
    "    maxy = np.amax(x[:,1])\n",
    "    minx = np.amin(x[:,0])\n",
    "    miny = np.amin(x[:,1])    \n",
    "    t = np.arange(minx-1, maxx+1, 0.1)\n",
    "    s = np.arange(miny-1, maxy+1, 0.1)\n",
    "    p,q = np.meshgrid(t, s)\n",
    "    z = SVMfunc_NL(np.stack((p,q), axis=2),x,y,beta,bias,kernel)\n",
    "    plt.contourf(t,s,z,[-99999,0,99999], colors=['blue','red'],alpha=0.5)\n",
    "    plt.plot(x[y==-1][:,0],x[y==-1][:,1],'bo',x[y==1][:,0],x[y==1][:,1],'ro')\n",
    "    \n",
    "conplot_NL(X_Data,Y_Data,1000,10,Gauss1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load MNIST Data\n",
    "import os\n",
    "import gzip\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def download(filename , source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve (source + filename , filename)\n",
    "    \n",
    "\n",
    "def load_mnist_images (filename):\n",
    "    if not os.path.exists(filename ):\n",
    "        download(filename)\n",
    "    with gzip.open(filename , 'rb') as f:\n",
    "        data = np. frombuffer (f.read (), np.uint8 , offset=16)\n",
    "    data = data.reshape (-1, 28, 28)\n",
    "    return data / np.float32 (256)\n",
    "\n",
    "def load_mnist_labels (filename):\n",
    "    if not os.path.exists(filename ):\n",
    "        download(filename)\n",
    "    with gzip.open(filename , 'rb') as f:\n",
    "        data = np. frombuffer (f.read (), np.uint8 , offset=8)\n",
    "    return data\n",
    "\n",
    "X_train = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "y_train = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "X_test = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "y_test = load_mnist_labels('t10k-labels-idx1-ubyte.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Sample(n,X,Y):\n",
    "    TrainSize=np.size(Y)\n",
    "    Choice=np.random.choice(TrainSize,n)\n",
    "    return (X[Choice,:],Y[Choice])\n",
    "    \n",
    "def CrossValidation(X_train,y_train):\n",
    "    X_validate,y_validate=Sample(500,X_train,y_train)\n",
    "    \n",
    "    para= {'C':[1,10,100], 'gamma':[0.1,0.01,0.001]}\n",
    "    svc = svm.SVC()\n",
    "    Searchclf = GridSearchCV(svc, para, cv=5)\n",
    "    Searchclf.fit(X_validate, y_validate)\n",
    "    \n",
    "    return Searchclf.best_params_\n",
    "\n",
    "def SciKitSVM(X_train,y_train,X_test,y_test):\n",
    "    X_test=X_test.reshape(X_test.shape[0],28*28)\n",
    "    X_train=X_train.reshape(X_train.shape[0],28*28)\n",
    "    \n",
    "    X_trainSubset,y_trainSubset=Sample(2000,X_train,y_train)\n",
    "    \n",
    "    params=CrossValidation(X_train,y_train)   \n",
    "    clf = svm.SVC(C=params['C'],gamma=params['gamma'])\n",
    "\n",
    "    clf.fit(X_trainSubset, y_trainSubset)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    conf= metrics.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "    print(conf)\n",
    "    print(np.trace(conf)/y_test.size)\n",
    "    \n",
    "SciKitSVM(X_train,y_train,X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is our approach of picking a different training set in step (b) – and learning\n",
    "with the optimal parameters from (a) – valid? Are there potential pitfalls?\n",
    "\n",
    "The approach is valid. We assume the data from a) and b) are both drawn from the same probability distribution so optimality for a) should carry over to the data used in b). Since we train many times to optimise parameters its only paractical with smaller subsets but when we train using the optimal parameters we can use much more data practically. Doing it this way should also help avoid overfitting. \n",
    "\n",
    "If our data set in a) is not a good representation of all the data, perhaps too small or not random, this could give us bad parameters which could make our final predictor much less accurate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
