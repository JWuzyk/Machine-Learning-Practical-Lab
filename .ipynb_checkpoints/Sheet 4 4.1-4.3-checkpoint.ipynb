{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for Keras tasks of sheet 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Normalize it\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "# Store it in the correct format for Keras\n",
    "# The image data has a single channel (grayscale values)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "# Store the labels in the correct format for Keras\n",
    "Y_train = keras.utils.np_utils.to_categorical(y_train, 10)\n",
    "Y_test = keras.utils.np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `X_train` for fully-connected inputs, reshape it. Use the `input_shape` variable in the first layer of your networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \"\"\"Create a plot showing the training history of `model.fit`.\n",
    "    \n",
    "    Example:\n",
    "        history = model.fit(...)\n",
    "        plot_history(history)\n",
    "    \"\"\"\n",
    "    x = range(history.params['epochs'])\n",
    "    acc, val_acc = history.history['acc'], history.history.get('val_acc')\n",
    "    f, axarr = plt.subplots(2, sharex=True)\n",
    "    axarr[0].set_title('accuracy')\n",
    "    axarr[0].plot(x, acc, label='train')\n",
    "    if val_acc:\n",
    "        axarr[0].plot(x, val_acc, label='validation')\n",
    "    axarr[0].legend()\n",
    "    \n",
    "    loss, val_loss = history.history['loss'], history.history.get('val_loss')\n",
    "    axarr[1].set_title('loss')\n",
    "    axarr[1].plot(x, loss, label='train')\n",
    "    if val_loss:\n",
    "        axarr[1].plot(x, val_loss, label='validation')\n",
    "    axarr[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4.1-4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conplot(NN, value=0, maxx=2, minx=-2, maxy=2, miny=-2):\n",
    " \n",
    "    #create meshgrid using the given min and max x,y values\n",
    "    t = np.arange(minx-1, maxx+1, 0.1)\n",
    "    s = np.arange(miny-1, maxy+1, 0.1)\n",
    "    p,q = np.meshgrid(t, s)\n",
    "    \n",
    "    funcArgs = np.array([p.flatten(), q.flatten()]).T\n",
    "    print(funcArgs.shape)\n",
    "    r = NN.ff(funcArgs)\n",
    "    r= np.reshape(r, p.shape)\n",
    "    \n",
    "    plt.contourf(t,s,r,[-99999,value,99999], colors=['blue','red'],alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class id:\n",
    "    def __init__(self):\n",
    "        print('hi')\n",
    "\n",
    "    def eval(x):\n",
    "        return x\n",
    "    def der(x):\n",
    "        return np.ones(x.shape)\n",
    "\n",
    "class relu:\n",
    "    def __init__(self):\n",
    "        print('hi')\n",
    "    \n",
    "    def eval(x):\n",
    "        return np.maximum(x,0)\n",
    "    \n",
    "    def der(x):\n",
    "        x[np.maximum(x,0)==0]=0\n",
    "        x[np.maximum(x,0) != 0]=1\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "class TwoLayerNN:\n",
    "    def __init__(self,Data_X,Data_Y, nu =0.1, K = 10 , d_2 = 20, phi_2 = relu, phi_3 = id):\n",
    "        #Data,learning rate , Batch size , Steps, numer of neurons, first activation function, second activation function\n",
    "        self.Data_X = Data_X\n",
    "        self.Data_Y = Data_Y\n",
    "        self.nu= nu\n",
    "        self.K = K\n",
    "        self.Steps = Steps\n",
    "        self.d_1 = Data_X.shape[1]\n",
    "        self.d_2 = d_2\n",
    "        self.phi_2 = phi_2\n",
    "        self.phi_3 = phi_3\n",
    "        self.weights_1 = np.random.uniform(-1,1, (self.d_1,self.d_2))\n",
    "        self.weights_2 = np.random.uniform(-1,1, (self.d_2,1))\n",
    "        self.bias_1 = np.random.uniform(-1,1, (self.d_2,1))\n",
    "        self.bias_2 = np.random.uniform(-1,1)\n",
    "        \n",
    "    def ff(self,x):\n",
    "        o_1 = x.reshape(x.shape[0],1,x.shape[1])\n",
    "        net_2= o_1 @ self.weights_1\n",
    "        net_2 += self.bias_1.reshape((1,1,self.d_2))\n",
    "        o_2 = self.phi_2.eval(net_2)\n",
    "        net_3 = o_2 @ self.weights_2 + self.bias_2\n",
    "        o_3 = self.phi_3.eval(net_3)\n",
    "        return o_3\n",
    "        \n",
    "    def backprop(self,x,y):\n",
    "        o_1 = x.reshape(x.shape[0],1,x.shape[1])\n",
    "        net_2= o_1 @ self.weights_1\n",
    "        net_2 += self.bias_1.reshape((1,1,self.d_2))\n",
    "        o_2 = self.phi_2.eval(net_2)\n",
    "        net_3 = o_2 @ self.weights_2 + self.bias_2\n",
    "        o_3 = self.phi_3.eval(net_3)\n",
    "        \n",
    "        delta_2 = 2*(o_3 - y.reshape(y.shape[0],1,1))\n",
    "        delta_1 = (delta_2* self.phi_3.der(net_3)) @ self.weights_2.T\n",
    "        delta_0 = (delta_1 * self.phi_2.der(net_2)) @ self.weights_1.T\n",
    "        grad_W1= o_1 * (delta_1 * self.phi_2.der(net_2)).reshape(self.K,self.d_2,1)\n",
    "        grad_W2= o_2 * (delta_2 * self.phi_3.der(net_3))\n",
    "        \n",
    "        grad_b1= delta_1 * self.phi_2.der(net_2)\n",
    "        grad_b2= delta_2 * self.phi_3.der(net_3)\n",
    "        \n",
    "        self.weights_1 = self.weights_1 - (1/self.K)*self.nu*np.sum(grad_W1,axis=0).T\n",
    "        self.weights_2 =self.weights_2 - (1/self.K)*self.nu*np.sum(grad_W2,axis=0).T\n",
    "        self.bias_1 = self.bias_1 - (1/self.K)*self.nu*np.sum(grad_b1,axis=0).T\n",
    "        self.bias_2 =self.bias_2 - (1/self.K)*self.nu*np.sum(grad_b2,axis=0).T\n",
    "        \n",
    "    def StocGradDesc(self):\n",
    "        Batch_X,Batch_Y = self.DrawBatch()\n",
    "        self.backprop(Batch_X,Batch_Y)\n",
    "        \n",
    "        \n",
    "    def DrawBatch(self):\n",
    "        C = np.random.randint(0,self.Data_X.shape[0],(self.K))\n",
    "        return self.Data_X[C],self.Data_Y[C]\n",
    "    \n",
    "    def LSE(self):\n",
    "        return (1/self.Data_X.shape[0])*np.sum((self.ff(self.Data_X)-self.Data_Y.reshape((self.Data_Y.shape[0],1,1)))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data, take a uniform distribution on [0,1]x[0,2\\pi], scale 1st coord by sqrt( to get uniform dist on disk) and map to circle using polar coords\n",
    "\n",
    "n= 250 #number of samples\n",
    "x= np.random.uniform(0,1,n)\n",
    "x=x**0.5\n",
    "y= np.random.uniform(0,2*np.pi,n)\n",
    "yd=x*np.sin(y)\n",
    "xd=x*np.cos(y)\n",
    "X1= np.vstack((xd,yd)).T\n",
    "X1lbl=-1*np.ones(n)\n",
    "\n",
    "#similarly for annulus\n",
    "x= np.random.uniform(1,4,n)\n",
    "x=x**0.5\n",
    "y= np.random.uniform(0,2*np.pi,n)\n",
    "yd=x*np.sin(y)\n",
    "xd=x*np.cos(y)\n",
    "X2= np.vstack((xd,yd)).T\n",
    "X2lbl=np.ones(n)\n",
    "#label X1 by -1 and X2 by 1\n",
    "\n",
    "\n",
    "X_Data = np.concatenate((X1,X2))\n",
    "Y_Data = np.concatenate((X1lbl,X2lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares error after 0 itterations: 16.70413463632029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\janwu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:59: RuntimeWarning: overflow encountered in matmul\n",
      "c:\\users\\janwu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: invalid value encountered in multiply\n",
      "c:\\users\\janwu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:60: RuntimeWarning: overflow encountered in matmul\n",
      "c:\\users\\janwu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:61: RuntimeWarning: invalid value encountered in multiply\n",
      "c:\\users\\janwu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:62: RuntimeWarning: overflow encountered in multiply\n",
      "c:\\users\\janwu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares error after 5000 itterations: nan\n",
      "Least squares error after 10000 itterations: nan\n",
      "Least squares error after 15000 itterations: nan\n",
      "Least squares error after 20000 itterations: nan\n",
      "Least squares error after 25000 itterations: nan\n"
     ]
    }
   ],
   "source": [
    "Steps = 20*5000\n",
    "NN= TwoLayerNN(X_Data,Y_Data,nu=1)\n",
    "for i in range(Steps):\n",
    "    NN.StocGradDesc()\n",
    "    if i % 5000 == 0:\n",
    "        print(f\"Least squares error after {i} itterations: {NN.LSE()}\")\n",
    "        \n",
    "print(f\"final Least squares error: {NN.LSE()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conplot(NN)\n",
    "plt.plot(X_Data[Y_Data==-1][:,0],X_Data[Y_Data==-1][:,1],'bo',markersize=3)\n",
    "plt.plot(X_Data[Y_Data==1][:,0],X_Data[Y_Data==1][:,1],'ro',markersize=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nu = 0.01 S = 200 * 5000, final LSE = 0.109\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
